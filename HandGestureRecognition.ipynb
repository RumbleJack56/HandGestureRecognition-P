{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gesture-Recognition System For Drones**\n",
    "\n",
    "## **Goal:**\n",
    "Efficiently using a machine learning model and Mediapipe for hand-landmarking to create a system that can reliably predict hand gestures that pass on movement data to the drone.\n",
    "\n",
    "## **The gestures:**\n",
    "We will be using a total of 8 gestures to make the tello run\n",
    "Gestures used are:\n",
    "<div style=\"display: inline-block; margin-right: 10%; max-width: 200px; float: right;\">\n",
    "<img\n",
    "  src=\"https://s-cdn.ryzerobotics.com/stormsend/uploads/13433930-d1e1-0135-d3c1-12530322f90d/guava-%E7%99%BD-pc-160_154_2x.png\"\n",
    "  alt=\"Drone Image\"\n",
    "  title=\"Fig.1 Drone\"\n",
    "  style=\"border-radius:5%;\"><p align=\"center\">Fig.1 Drone</p>\n",
    "</div>\n",
    "\n",
    "1. ```Up     - Point Upwards                         (2)```\n",
    "2. ```Down   - Point Downwards                       (2)```\n",
    "3. ```Left   - Point to Left                         (2)```\n",
    "4. ```Right  - Point to Right                        (2)```\n",
    "5. ```Front  - Flatten hand and Point Forward        (2)```\n",
    "6. ```Back   - Thumb and Pinky Finger out            (2)```\n",
    "7. ```Land   - Okay sign                             (2)```\n",
    "8. ```Flip   - Yo! sign                              (4)```\n",
    "\n",
    "\n",
    "#### This is  a **four-part project** and the dataset of this is available on kaggle.\n",
    "The github repository of the project is:<br>\n",
    "[https://github.com/RumbleJack56/HandGestureRecognition-P](https://github.com/RumbleJack56/HandGestureRecognition-P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: Data-Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect data using ```opencv``` library and use ```cv2.VideoCapture()``` for accessing camera to take images of different gestures as training examples.<br>\n",
    "First lets import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\College\\S2-even\\ML\\Project\\HandGestureRecognition-P\n"
     ]
    }
   ],
   "source": [
    "#importing dependencies\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We check for **webcams**\n",
    "* Then select the webcam\n",
    "* and then we click picture every button press (s) and save it in dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_list = ['back1', 'back2', 'down1', 'down2', 'flip1', 'flip2', 'flip3', 'flip4', 'front1', 'front2', 'land1', 'land2', 'left1', 'left2', 'right1', 'right2', 'up1', 'up2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_cameras = list(filter(lambda x:cv2.VideoCapture(x) and cv2.VideoCapture(x).isOpened(),range(6)))\n",
    "gesture_list = os.listdir(\".dataset/\")\n",
    "maxEntries = 100\n",
    "print(\"Available Cameras at ports : \",*available_cameras)\n",
    "print(\"Gestures to record are :\", gesture_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame is 480 by 480, we add an additional 20px on top to accomodate the texts that serve as pointers for image clicking.<br>\n",
    "```cv2.keyWait()``` is used for keypress detection<br>\n",
    "There are 18 gestures in total.\n",
    "the image number and type are shown uptop on the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(available_cameras[0])\n",
    "mainFrame = np.zeros(500*480*3,dtype=np.uint8).reshape(500,480,3)\n",
    "entryNum = 1\n",
    "\n",
    "for gesture in gesture_list:\n",
    "    mainFrame[0:20,:200,:] = np.zeros(20*200*3).reshape(20,200,3)\n",
    "    cv2.putText(mainFrame,f\"Save with S | Quit with Q\",[200,15],0,0.5,[255,255,255])\n",
    "    cv2.putText(mainFrame,f\"{gesture}  Img:{entryNum}\",[20,15],0,0.5,[255,255,255])\n",
    "    while entryNum<=maxEntries:\n",
    "        ret , frame = cap.read()\n",
    "        mainFrame[20:,:,:] = frame[0:480,79:559,:]\n",
    "        cv2.imshow(\"frame\",mainFrame)\n",
    "\n",
    "        inp = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "        if inp == ord(\"s\"):\n",
    "            mainFrame[0:20,:200,:] = np.zeros(20*200*3).reshape(20,200,3)\n",
    "            cv2.putText(mainFrame,f\"{gesture}  Img:{entryNum}\",[20,15],0,0.5,[255,255,255])\n",
    "            cv2.imwrite(f\".dataset/{gesture}/{entryNum}.jpg\", frame[:,79:559,:])\n",
    "            entryNum+=1\n",
    "        if inp == ord(\"q\"):\n",
    "            break\n",
    "    entryNum=1\n",
    "    mainFrame[0:20,:200,:] = np.zeros(20*200*3).reshape(20,200,3)\n",
    "    cv2.putText(mainFrame,f\"waiting 3 sec\",[20,15],0,0.5,[255,255,255])\n",
    "    cv2.imshow(\"frame\",mainFrame)\n",
    "    time.sleep(3)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we have the dataset containing 200imgs/gesture for a total for 1800 images\n",
    "* Using MediaPipe, we can implement a program to convert these images into points on the hand\n",
    "* We take the point, and the detail whether the hand is left or right hand as columns of a dataframe\n",
    "* We save the Dataframe as a csv file\n",
    "\n",
    "##### **First we import the necessary libraries :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\College\\S2-even\\ML\\Project\\HandGestureRecognition-P\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from mediapipe import tasks,Image,solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://developers.google.com/static/mediapipe/images/solutions/hand-landmarks.png\" width=\"800\" height=\"300\" alt=\"Hand Landmarker Image (not loaded)\" style=\"float:right;border-radius:30px;\">\n",
    "\n",
    "**Mediapipe** provides us with a handlandmarker class, that takes a *landmarker.task* file as an object.<br> It uses that to find the points on the hand\n",
    "There are **21 points** on the hand.<br>\n",
    "They are shown in the image.<br>\n",
    "We first define some functions to *convert image to coordinates*.<br>\n",
    "Then we initialize the dataframe to save the coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = tasks.BaseOptions\n",
    "HandLandmarker = tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = tasks.vision.HandLandmarkerOptions\n",
    "VisionMode_IMAGE = tasks.vision.RunningMode.IMAGE\n",
    "\n",
    "#define conversion Function\n",
    "def convertToCords(img):\n",
    "    landmarker_options = HandLandmarkerOptions(base_options=BaseOptions(model_asset_path=\"handlandmarker/hand_landmarker.task\"),\n",
    "                                           num_hands=1,\n",
    "                                           running_mode=VisionMode_IMAGE)\n",
    "    detector = HandLandmarker.create_from_options(landmarker_options)\n",
    "    image = Image.create_from_file(img)\n",
    "    rawOutput = detector.detect(image)\n",
    "    \n",
    "    if len(rawOutput.hand_landmarks)==0:\n",
    "        return [0]*43 , rawOutput\n",
    "    cords = [[pt.x,pt.y] for h in rawOutput.hand_landmarks for pt in h]\n",
    "    hands = [x.category_name for y in rawOutput.handedness for x in y]\n",
    "    hands = [0 if a.lower()==\"left\" else 1 for a in hands]\n",
    "    cords = np.array(cords).reshape(-1)\n",
    "    return np.concatenate([hands,cords]) , rawOutput\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(columns = [\"Gesture\",\"Specific\",\"Hand\"]+[a+str(b) for b in range(1,22)for a in \"xy\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We append each file which is successfully detected a hand into the dataframe and save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_list = os.listdir(\".dataset/\")\n",
    "errors = []\n",
    "c=0\n",
    "for gesture in gesture_list:\n",
    "    for img in os.listdir(\".dataset/\"+gesture+\"/\"):\n",
    "        coords , raw = convertToCords(f\".dataset/{gesture}/{img}\")\n",
    "        if list(coords).count(0) > 10:\n",
    "            errors.append([gesture,img,coords])\n",
    "            continue\n",
    "        findat = [\"\".join(filter(lambda x:not x.isnumeric(),gesture)),gesture] + list(coords)\n",
    "        print(findat,len(findat))\n",
    "        df.loc[c] = findat\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Specific</th>\n",
       "      <th>Hand</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y5</th>\n",
       "      <th>x6</th>\n",
       "      <th>y6</th>\n",
       "      <th>x7</th>\n",
       "      <th>y7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y8</th>\n",
       "      <th>x9</th>\n",
       "      <th>y9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y10</th>\n",
       "      <th>x11</th>\n",
       "      <th>y11</th>\n",
       "      <th>x12</th>\n",
       "      <th>y12</th>\n",
       "      <th>x13</th>\n",
       "      <th>y13</th>\n",
       "      <th>x14</th>\n",
       "      <th>y14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y15</th>\n",
       "      <th>x16</th>\n",
       "      <th>y16</th>\n",
       "      <th>x17</th>\n",
       "      <th>y17</th>\n",
       "      <th>x18</th>\n",
       "      <th>y18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back</td>\n",
       "      <td>back1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414146</td>\n",
       "      <td>0.612191</td>\n",
       "      <td>0.328202</td>\n",
       "      <td>0.509499</td>\n",
       "      <td>0.274394</td>\n",
       "      <td>0.378656</td>\n",
       "      <td>0.235361</td>\n",
       "      <td>0.280007</td>\n",
       "      <td>0.172614</td>\n",
       "      <td>0.232476</td>\n",
       "      <td>0.417589</td>\n",
       "      <td>0.305328</td>\n",
       "      <td>0.478275</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.447562</td>\n",
       "      <td>0.327513</td>\n",
       "      <td>0.413079</td>\n",
       "      <td>0.384554</td>\n",
       "      <td>0.492442</td>\n",
       "      <td>0.339574</td>\n",
       "      <td>0.545159</td>\n",
       "      <td>0.286216</td>\n",
       "      <td>0.491170</td>\n",
       "      <td>0.383502</td>\n",
       "      <td>0.450574</td>\n",
       "      <td>0.436260</td>\n",
       "      <td>0.557899</td>\n",
       "      <td>0.376470</td>\n",
       "      <td>0.615387</td>\n",
       "      <td>0.327836</td>\n",
       "      <td>0.549380</td>\n",
       "      <td>0.412990</td>\n",
       "      <td>0.496268</td>\n",
       "      <td>0.462539</td>\n",
       "      <td>0.611348</td>\n",
       "      <td>0.414597</td>\n",
       "      <td>0.677527</td>\n",
       "      <td>0.330069</td>\n",
       "      <td>0.720912</td>\n",
       "      <td>0.286768</td>\n",
       "      <td>0.765386</td>\n",
       "      <td>0.237655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>back</td>\n",
       "      <td>back1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370650</td>\n",
       "      <td>0.610049</td>\n",
       "      <td>0.298608</td>\n",
       "      <td>0.504365</td>\n",
       "      <td>0.243131</td>\n",
       "      <td>0.383307</td>\n",
       "      <td>0.198213</td>\n",
       "      <td>0.276979</td>\n",
       "      <td>0.130233</td>\n",
       "      <td>0.221631</td>\n",
       "      <td>0.393534</td>\n",
       "      <td>0.307553</td>\n",
       "      <td>0.453799</td>\n",
       "      <td>0.268997</td>\n",
       "      <td>0.417932</td>\n",
       "      <td>0.352670</td>\n",
       "      <td>0.377661</td>\n",
       "      <td>0.397066</td>\n",
       "      <td>0.462743</td>\n",
       "      <td>0.344746</td>\n",
       "      <td>0.514734</td>\n",
       "      <td>0.312115</td>\n",
       "      <td>0.452130</td>\n",
       "      <td>0.403362</td>\n",
       "      <td>0.417195</td>\n",
       "      <td>0.434952</td>\n",
       "      <td>0.522675</td>\n",
       "      <td>0.387920</td>\n",
       "      <td>0.579721</td>\n",
       "      <td>0.356566</td>\n",
       "      <td>0.508486</td>\n",
       "      <td>0.435011</td>\n",
       "      <td>0.453792</td>\n",
       "      <td>0.472075</td>\n",
       "      <td>0.566888</td>\n",
       "      <td>0.430045</td>\n",
       "      <td>0.642149</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.692941</td>\n",
       "      <td>0.333702</td>\n",
       "      <td>0.745193</td>\n",
       "      <td>0.293637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>back</td>\n",
       "      <td>back1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473404</td>\n",
       "      <td>0.610534</td>\n",
       "      <td>0.403636</td>\n",
       "      <td>0.540998</td>\n",
       "      <td>0.336039</td>\n",
       "      <td>0.457764</td>\n",
       "      <td>0.274731</td>\n",
       "      <td>0.383794</td>\n",
       "      <td>0.208107</td>\n",
       "      <td>0.352572</td>\n",
       "      <td>0.441720</td>\n",
       "      <td>0.354440</td>\n",
       "      <td>0.492019</td>\n",
       "      <td>0.326441</td>\n",
       "      <td>0.486615</td>\n",
       "      <td>0.402027</td>\n",
       "      <td>0.467288</td>\n",
       "      <td>0.446365</td>\n",
       "      <td>0.505381</td>\n",
       "      <td>0.367606</td>\n",
       "      <td>0.549151</td>\n",
       "      <td>0.344474</td>\n",
       "      <td>0.524393</td>\n",
       "      <td>0.429126</td>\n",
       "      <td>0.500389</td>\n",
       "      <td>0.467755</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.387625</td>\n",
       "      <td>0.604363</td>\n",
       "      <td>0.359324</td>\n",
       "      <td>0.570785</td>\n",
       "      <td>0.435650</td>\n",
       "      <td>0.537248</td>\n",
       "      <td>0.476573</td>\n",
       "      <td>0.602514</td>\n",
       "      <td>0.409813</td>\n",
       "      <td>0.652023</td>\n",
       "      <td>0.339880</td>\n",
       "      <td>0.688451</td>\n",
       "      <td>0.302070</td>\n",
       "      <td>0.722174</td>\n",
       "      <td>0.258313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>back</td>\n",
       "      <td>back1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404165</td>\n",
       "      <td>0.591113</td>\n",
       "      <td>0.323498</td>\n",
       "      <td>0.500862</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>0.386378</td>\n",
       "      <td>0.194849</td>\n",
       "      <td>0.297057</td>\n",
       "      <td>0.122084</td>\n",
       "      <td>0.254426</td>\n",
       "      <td>0.400766</td>\n",
       "      <td>0.296457</td>\n",
       "      <td>0.453977</td>\n",
       "      <td>0.256672</td>\n",
       "      <td>0.428348</td>\n",
       "      <td>0.346314</td>\n",
       "      <td>0.396861</td>\n",
       "      <td>0.396004</td>\n",
       "      <td>0.474016</td>\n",
       "      <td>0.323633</td>\n",
       "      <td>0.517238</td>\n",
       "      <td>0.295042</td>\n",
       "      <td>0.468126</td>\n",
       "      <td>0.392140</td>\n",
       "      <td>0.432252</td>\n",
       "      <td>0.433274</td>\n",
       "      <td>0.536755</td>\n",
       "      <td>0.356948</td>\n",
       "      <td>0.585354</td>\n",
       "      <td>0.324204</td>\n",
       "      <td>0.527779</td>\n",
       "      <td>0.409341</td>\n",
       "      <td>0.481247</td>\n",
       "      <td>0.451517</td>\n",
       "      <td>0.585874</td>\n",
       "      <td>0.391966</td>\n",
       "      <td>0.654301</td>\n",
       "      <td>0.317290</td>\n",
       "      <td>0.703211</td>\n",
       "      <td>0.279311</td>\n",
       "      <td>0.751139</td>\n",
       "      <td>0.231592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back</td>\n",
       "      <td>back1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438877</td>\n",
       "      <td>0.565304</td>\n",
       "      <td>0.365005</td>\n",
       "      <td>0.479435</td>\n",
       "      <td>0.295897</td>\n",
       "      <td>0.372908</td>\n",
       "      <td>0.227563</td>\n",
       "      <td>0.281984</td>\n",
       "      <td>0.147816</td>\n",
       "      <td>0.245443</td>\n",
       "      <td>0.427087</td>\n",
       "      <td>0.272703</td>\n",
       "      <td>0.498420</td>\n",
       "      <td>0.237385</td>\n",
       "      <td>0.484256</td>\n",
       "      <td>0.318174</td>\n",
       "      <td>0.450644</td>\n",
       "      <td>0.366944</td>\n",
       "      <td>0.500393</td>\n",
       "      <td>0.296554</td>\n",
       "      <td>0.558035</td>\n",
       "      <td>0.270496</td>\n",
       "      <td>0.519303</td>\n",
       "      <td>0.359943</td>\n",
       "      <td>0.479609</td>\n",
       "      <td>0.402161</td>\n",
       "      <td>0.562462</td>\n",
       "      <td>0.327223</td>\n",
       "      <td>0.623040</td>\n",
       "      <td>0.296477</td>\n",
       "      <td>0.575185</td>\n",
       "      <td>0.375263</td>\n",
       "      <td>0.526642</td>\n",
       "      <td>0.418887</td>\n",
       "      <td>0.608410</td>\n",
       "      <td>0.358565</td>\n",
       "      <td>0.672683</td>\n",
       "      <td>0.287383</td>\n",
       "      <td>0.719293</td>\n",
       "      <td>0.249577</td>\n",
       "      <td>0.762312</td>\n",
       "      <td>0.205041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>up</td>\n",
       "      <td>up2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.318180</td>\n",
       "      <td>0.760065</td>\n",
       "      <td>0.413418</td>\n",
       "      <td>0.760018</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.695766</td>\n",
       "      <td>0.584936</td>\n",
       "      <td>0.641249</td>\n",
       "      <td>0.652940</td>\n",
       "      <td>0.616664</td>\n",
       "      <td>0.476888</td>\n",
       "      <td>0.538831</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.433714</td>\n",
       "      <td>0.497844</td>\n",
       "      <td>0.367536</td>\n",
       "      <td>0.495844</td>\n",
       "      <td>0.312925</td>\n",
       "      <td>0.407003</td>\n",
       "      <td>0.509364</td>\n",
       "      <td>0.416092</td>\n",
       "      <td>0.548843</td>\n",
       "      <td>0.399864</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.388385</td>\n",
       "      <td>0.668507</td>\n",
       "      <td>0.337585</td>\n",
       "      <td>0.514801</td>\n",
       "      <td>0.350348</td>\n",
       "      <td>0.579631</td>\n",
       "      <td>0.347047</td>\n",
       "      <td>0.649710</td>\n",
       "      <td>0.347737</td>\n",
       "      <td>0.675092</td>\n",
       "      <td>0.275496</td>\n",
       "      <td>0.534110</td>\n",
       "      <td>0.295744</td>\n",
       "      <td>0.579818</td>\n",
       "      <td>0.304097</td>\n",
       "      <td>0.639276</td>\n",
       "      <td>0.311401</td>\n",
       "      <td>0.661359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>up</td>\n",
       "      <td>up2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333133</td>\n",
       "      <td>0.765357</td>\n",
       "      <td>0.433654</td>\n",
       "      <td>0.750039</td>\n",
       "      <td>0.528928</td>\n",
       "      <td>0.673653</td>\n",
       "      <td>0.591601</td>\n",
       "      <td>0.612895</td>\n",
       "      <td>0.651415</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>0.474883</td>\n",
       "      <td>0.525129</td>\n",
       "      <td>0.477423</td>\n",
       "      <td>0.417132</td>\n",
       "      <td>0.470425</td>\n",
       "      <td>0.345884</td>\n",
       "      <td>0.461055</td>\n",
       "      <td>0.287999</td>\n",
       "      <td>0.402714</td>\n",
       "      <td>0.500945</td>\n",
       "      <td>0.412038</td>\n",
       "      <td>0.534246</td>\n",
       "      <td>0.406168</td>\n",
       "      <td>0.620228</td>\n",
       "      <td>0.399233</td>\n",
       "      <td>0.667343</td>\n",
       "      <td>0.332708</td>\n",
       "      <td>0.510996</td>\n",
       "      <td>0.346669</td>\n",
       "      <td>0.567924</td>\n",
       "      <td>0.351486</td>\n",
       "      <td>0.641314</td>\n",
       "      <td>0.354265</td>\n",
       "      <td>0.676793</td>\n",
       "      <td>0.270657</td>\n",
       "      <td>0.533770</td>\n",
       "      <td>0.290863</td>\n",
       "      <td>0.575671</td>\n",
       "      <td>0.304575</td>\n",
       "      <td>0.634753</td>\n",
       "      <td>0.314181</td>\n",
       "      <td>0.660901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>up</td>\n",
       "      <td>up2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.359078</td>\n",
       "      <td>0.772219</td>\n",
       "      <td>0.462878</td>\n",
       "      <td>0.744825</td>\n",
       "      <td>0.550234</td>\n",
       "      <td>0.657884</td>\n",
       "      <td>0.606673</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.665992</td>\n",
       "      <td>0.555741</td>\n",
       "      <td>0.476407</td>\n",
       "      <td>0.511747</td>\n",
       "      <td>0.471551</td>\n",
       "      <td>0.400755</td>\n",
       "      <td>0.461377</td>\n",
       "      <td>0.332231</td>\n",
       "      <td>0.450677</td>\n",
       "      <td>0.277905</td>\n",
       "      <td>0.403008</td>\n",
       "      <td>0.497380</td>\n",
       "      <td>0.424101</td>\n",
       "      <td>0.529585</td>\n",
       "      <td>0.424281</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>0.418132</td>\n",
       "      <td>0.661633</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>0.513233</td>\n",
       "      <td>0.364106</td>\n",
       "      <td>0.570689</td>\n",
       "      <td>0.371530</td>\n",
       "      <td>0.644089</td>\n",
       "      <td>0.372024</td>\n",
       "      <td>0.675554</td>\n",
       "      <td>0.278025</td>\n",
       "      <td>0.539133</td>\n",
       "      <td>0.309333</td>\n",
       "      <td>0.578653</td>\n",
       "      <td>0.325870</td>\n",
       "      <td>0.635492</td>\n",
       "      <td>0.332590</td>\n",
       "      <td>0.658003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>up</td>\n",
       "      <td>up2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361350</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.462772</td>\n",
       "      <td>0.749407</td>\n",
       "      <td>0.552244</td>\n",
       "      <td>0.666314</td>\n",
       "      <td>0.609610</td>\n",
       "      <td>0.600176</td>\n",
       "      <td>0.671599</td>\n",
       "      <td>0.564308</td>\n",
       "      <td>0.486660</td>\n",
       "      <td>0.515329</td>\n",
       "      <td>0.485570</td>\n",
       "      <td>0.405388</td>\n",
       "      <td>0.477345</td>\n",
       "      <td>0.336882</td>\n",
       "      <td>0.467720</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0.413424</td>\n",
       "      <td>0.497023</td>\n",
       "      <td>0.434099</td>\n",
       "      <td>0.533829</td>\n",
       "      <td>0.432243</td>\n",
       "      <td>0.623287</td>\n",
       "      <td>0.425796</td>\n",
       "      <td>0.666410</td>\n",
       "      <td>0.345723</td>\n",
       "      <td>0.511361</td>\n",
       "      <td>0.372192</td>\n",
       "      <td>0.574959</td>\n",
       "      <td>0.377984</td>\n",
       "      <td>0.648686</td>\n",
       "      <td>0.379364</td>\n",
       "      <td>0.675236</td>\n",
       "      <td>0.286465</td>\n",
       "      <td>0.537240</td>\n",
       "      <td>0.316468</td>\n",
       "      <td>0.582095</td>\n",
       "      <td>0.331279</td>\n",
       "      <td>0.640273</td>\n",
       "      <td>0.338255</td>\n",
       "      <td>0.659528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>up</td>\n",
       "      <td>up2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371123</td>\n",
       "      <td>0.762524</td>\n",
       "      <td>0.473363</td>\n",
       "      <td>0.741889</td>\n",
       "      <td>0.560114</td>\n",
       "      <td>0.657193</td>\n",
       "      <td>0.614916</td>\n",
       "      <td>0.589051</td>\n",
       "      <td>0.675875</td>\n",
       "      <td>0.553455</td>\n",
       "      <td>0.492568</td>\n",
       "      <td>0.507352</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.398182</td>\n",
       "      <td>0.479710</td>\n",
       "      <td>0.329744</td>\n",
       "      <td>0.469150</td>\n",
       "      <td>0.273401</td>\n",
       "      <td>0.419144</td>\n",
       "      <td>0.491752</td>\n",
       "      <td>0.434877</td>\n",
       "      <td>0.524117</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>0.613108</td>\n",
       "      <td>0.432873</td>\n",
       "      <td>0.656788</td>\n",
       "      <td>0.351247</td>\n",
       "      <td>0.506367</td>\n",
       "      <td>0.373140</td>\n",
       "      <td>0.561790</td>\n",
       "      <td>0.380542</td>\n",
       "      <td>0.637647</td>\n",
       "      <td>0.383867</td>\n",
       "      <td>0.667562</td>\n",
       "      <td>0.291894</td>\n",
       "      <td>0.530843</td>\n",
       "      <td>0.318843</td>\n",
       "      <td>0.569579</td>\n",
       "      <td>0.335379</td>\n",
       "      <td>0.630175</td>\n",
       "      <td>0.344544</td>\n",
       "      <td>0.653303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gesture Specific  Hand        x1  ...       x20       y20       x21       y21\n",
       "0       back    back1   0.0  0.414146  ...  0.720912  0.286768  0.765386  0.237655\n",
       "1       back    back1   0.0  0.370650  ...  0.692941  0.333702  0.745193  0.293637\n",
       "2       back    back1   0.0  0.473404  ...  0.688451  0.302070  0.722174  0.258313\n",
       "3       back    back1   0.0  0.404165  ...  0.703211  0.279311  0.751139  0.231592\n",
       "4       back    back1   0.0  0.438877  ...  0.719293  0.249577  0.762312  0.205041\n",
       "...      ...      ...   ...       ...  ...       ...       ...       ...       ...\n",
       "1777      up      up2   1.0  0.318180  ...  0.304097  0.639276  0.311401  0.661359\n",
       "1778      up      up2   1.0  0.333133  ...  0.304575  0.634753  0.314181  0.660901\n",
       "1779      up      up2   1.0  0.359078  ...  0.325870  0.635492  0.332590  0.658003\n",
       "1780      up      up2   1.0  0.361350  ...  0.331279  0.640273  0.338255  0.659528\n",
       "1781      up      up2   1.0  0.371123  ...  0.335379  0.630175  0.344544  0.653303\n",
       "\n",
       "[1782 rows x 45 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"csv/co-ordinates.csv\",index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Model Compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we have the dataframe with target Y = Gesture and parameters X = hand and x1 y1 z1 to x21 y21 z21\n",
    "* We One-Hot Encode the Gesture into an output vector of length 9\n",
    "* We take the input size as 64 inputs\n",
    "* Model used is a Dense Sequential Network with 128 , 64 , DropOut 0.2 , 64 , 32 , 9\n",
    "\n",
    "##### **First we import the necessary libraries :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import InputLayer,Dropout,Dense\n",
    "from tensorflow.nn import softmax\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "import pandas as pd,numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the data from the csv file and split it using train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_list = os.listdir(\".dataset/\")\n",
    "Xy = pd.read_csv(\"csv/co-ordinates.csv\")\n",
    "y_full = pd.DataFrame(map(lambda x: gesture_list.index(x),pd.DataFrame(Xy.loc[:,\"Specific\"]).to_numpy().reshape(-1).tolist()))\n",
    "X_full = Xy.drop([\"Specific\",\"Gesture\"],axis=1)\n",
    "X_train, X_valid, y_train,  y_valid = train_test_split(X_full,y_full,train_size=0.7,test_size=0.3,random_state=443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the model, and preview its summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\College\\S2-even\\ML\\Project\\HandGestureRecognition-P\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Gestures\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Gestures\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ PrimaryIN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Reducer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 80percent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Paralleler (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Reducer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">594</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ PrimaryIN (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Reducer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 80percent (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Paralleler (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Reducer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Out (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m594\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,722</span> (80.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,722\u001b[0m (80.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,722</span> (80.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,722\u001b[0m (80.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=[43]),\n",
    "    Dense(128,activation=\"relu\",kernel_regularizer=\"l2\",name=\"PrimaryIN\"),\n",
    "    Dense(64,activation=\"relu\",kernel_regularizer=\"l2\",name=\"Reducer1\"),\n",
    "    Dropout(0.2,name=\"80percent\"),\n",
    "    Dense(64,activation=\"relu\",name=\"Paralleler\"),\n",
    "    Dense(32,activation=\"relu\",name=\"Reducer2\"),\n",
    "    Dense(18,activation=\"linear\",name=\"Out\"),\n",
    "],name=\"Gestures\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we train the model. We use SparseCategoricalCrossentropy, because that allows us to do one-class classification in softmax based outputs.<br> We used logits here, so we could take the estimation values as well, and also apply thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9146 - loss: 0.8329 - val_accuracy: 1.0000 - val_loss: 0.6558\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.7582 - val_accuracy: 0.9981 - val_loss: 0.6155\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.7087 - val_accuracy: 0.9963 - val_loss: 0.5708\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.6820 - val_accuracy: 0.9944 - val_loss: 0.5489\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.6073 - val_accuracy: 0.9421 - val_loss: 0.5351\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.5797 - val_accuracy: 1.0000 - val_loss: 0.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c5d3a86290>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True),optimizer=Adam(1e-3),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid),callbacks=EarlyStopping(monitor='val_accuracy',patience=5,restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test in for the validation set. <br>\n",
    "Since the hyperparameters are tuned well for the model, by iterative testing and intuition. <br>\n",
    "The accuracy achieved is significantly high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.predict(X_valid)\n",
    "p = [[np.argmax(softmax(x)),max(softmax(x)).numpy()] for x in a]\n",
    "q = y_valid.to_numpy()\n",
    "testpreds = [np.argmax(softmax(x)) for x in a]\n",
    "acc = Accuracy(name=\"accuracy\")\n",
    "acc.update_state(testpreds,q)\n",
    "acc.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a 100% validation accuracy which allows us to conclude that the model is highly accurate.<br>\n",
    "We save this model in the models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/main3.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 4: Live Working**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have trained and saved a model which has high accuracy\n",
    "* We will load that model, and predict using live_stream mediapipe\n",
    "* present output in an opencv window\n",
    "\n",
    "##### **First we import the necessary libraries :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.nn import softmax\n",
    "import cv2,numpy as np,time,os\n",
    "from mediapipe import Image,tasks,solutions,ImageFormat\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Cameras at ports :  0 2\n"
     ]
    }
   ],
   "source": [
    "available_cameras = list(filter(lambda x:cv2.VideoCapture(x) and cv2.VideoCapture(x).isOpened(),range(6)))\n",
    "print(\"Available Cameras at ports : \",*available_cameras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use code similar to coodinate conversion and Image Capturing.<br>\n",
    "This allows us to use the same format of input and output as before.<br>\n",
    "We feed this into the loaded model.<br>\n",
    "This allows us to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = tasks.BaseOptions\n",
    "HandLandmarker = tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = tasks.vision.HandLandmarkerOptions\n",
    "VisionMode_IMAGE = tasks.vision.RunningMode.IMAGE\n",
    "\n",
    "solution_landmark_style = solutions.drawing_styles.get_default_hand_landmarks_style\n",
    "solution_connection_style = solutions.drawing_styles.get_default_hand_connections_style\n",
    "\n",
    "def convertToCords(img):\n",
    "    landmarker_options = HandLandmarkerOptions(base_options=BaseOptions(model_asset_path=\"handlandmarker/hand_landmarker.task\"),\n",
    "                                           num_hands=1,\n",
    "                                           running_mode=VisionMode_IMAGE)\n",
    "    detector = HandLandmarker.create_from_options(landmarker_options)\n",
    "    \n",
    "    image = Image(image_format= ImageFormat.SRGB,data=img)\n",
    "    rawOutput = detector.detect(image)\n",
    "\n",
    "    \n",
    "    if len(rawOutput.hand_landmarks)==0:\n",
    "        return [0]*43 , rawOutput\n",
    "    cords = [[pt.x,pt.y] for h in rawOutput.hand_landmarks for pt in h]\n",
    "    hands = [x.category_name for y in rawOutput.handedness for x in y]\n",
    "    hands = [0 if a.lower()==\"left\" else 1 for a in hands]\n",
    "    cords = np.array(cords).reshape(-1)\n",
    "    return np.concatenate([hands,cords]) , rawOutput\n",
    "\n",
    "def showImg(img,detected_result):\n",
    "    for landmarks,handedness in zip(detected_result.hand_landmarks,detected_result.handedness):\n",
    "        proto_marks = landmark_pb2.NormalizedLandmarkList()\n",
    "        proto_marks.landmark.extend([landmark_pb2.NormalizedLandmark(x=L.x,y=L.y) for L in landmarks])\n",
    "        solutions.drawing_utils.draw_landmarks(img,proto_marks,solutions.hands.HAND_CONNECTIONS,solution_landmark_style(),solution_connection_style())\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the main loop and put the predictions with a threshold of 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right2 0.8377846 [[6.903024768689647e-05, 0.01303767692297697, 7.4356574941703e-07, 0.01790691167116165, 0.0013277461985126138, 0.0024760933592915535, 0.011225773021578789, 6.049272371910774e-08, 3.1776065156918776e-07, 8.305639312311541e-06, 1.6398884472579311e-09, 9.985136983914344e-08, 2.3774562578182667e-05, 0.0015103545738384128, 0.045435160398483276, 0.8377845883369446, 5.163367859495338e-06, 0.06918823719024658]] [1.0, 0.4161107540130615, 0.8581729531288147, 0.4449227750301361, 0.775661826133728, 0.534915566444397, 0.7258224487304688, 0.632540225982666, 0.727108359336853, 0.7016428709030151, 0.7390425205230713, 0.5146825909614563, 0.701450765132904, 0.6432111263275146, 0.6929610967636108, 0.7206109166145325, 0.6936841011047363, 0.7762658596038818, 0.6951579451560974, 0.5143750905990601, 0.7766696810722351, 0.6698098182678223, 0.7755172848701477, 0.7390329837799072, 0.772437334060669, 0.7804704308509827, 0.7667444944381714, 0.5190845727920532, 0.8543644547462463, 0.6705652475357056, 0.8553385138511658, 0.7238624691963196, 0.8392969369888306, 0.7452945113182068, 0.8232467174530029, 0.5270872712135315, 0.9233746528625488, 0.6387858390808105, 0.8965681195259094, 0.6842691898345947, 0.8806107044219971, 0.709465503692627, 0.8693763613700867]21953582764]8]9293460846]546]]86]664215564727783]]\r"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(available_cameras[0])\n",
    "mainFrame = np.zeros(550*600*3,dtype=np.uint8).reshape(550,600,3)\n",
    "model = load_model(\"models/main3.keras\")\n",
    "gesture_list = ['back1', 'back2', 'down1', 'down2', 'flip1', 'flip2', 'flip3', 'flip4', 'front1', 'front2', 'land1', 'land2', 'left1', 'left2', 'right1', 'right2', 'up1', 'up2']\n",
    "\n",
    "\n",
    "while True:\n",
    "    _ , frame = cap.read()\n",
    "    frame = frame[:,79:559,:]\n",
    "    pts , raw = convertToCords(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
    "    pickim = showImg(frame,raw)\n",
    "    conf=0\n",
    "    if len(raw.handedness)!=0:\n",
    "        preds = model.predict(np.array(pts).reshape(1,43),verbose=0)\n",
    "        softout = softmax(preds)\n",
    "        ans = gesture_list[np.argmax(softout)]\n",
    "        conf = np.max(softout.numpy())\n",
    "        print(ans ,conf, list(softout.numpy().tolist()) ,list(pts),end=\"\\r\")\n",
    "    \n",
    "    mainFrame[70:,79:559,:] = pickim\n",
    "    if conf > 0.5:\n",
    "        mainFrame[:70,:300,:] = np.zeros(70*300*3).reshape(70,300,3)\n",
    "        cv2.putText(mainFrame,f\"{ans}\",[20,20],0,0.5,color=[0,255,0])\n",
    "    else:\n",
    "        mainFrame[:70,:300,:] = np.zeros(70*300*3).reshape(70,300,3)\n",
    "        cv2.putText(mainFrame,f\"no strong detection\",[20,20],0,0.5,color=[0,0,255])\n",
    "\n",
    "    cv2.imshow(\"Frame\",mainFrame)\n",
    "\n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
